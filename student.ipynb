{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed for the project \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the data file\n",
    "\n",
    "data = pd.read_csv('./data/AirQualityUCI.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13,6</td>\n",
       "      <td>48,9</td>\n",
       "      <td>0,7578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13,3</td>\n",
       "      <td>47,7</td>\n",
       "      <td>0,7255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>54,0</td>\n",
       "      <td>0,7502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9,2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11,0</td>\n",
       "      <td>60,0</td>\n",
       "      <td>0,7867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11,2</td>\n",
       "      <td>59,6</td>\n",
       "      <td>0,7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "0  10/03/2004  18.00.00    2,6       1360.0     150.0     11,9         1046.0   \n",
       "1  10/03/2004  19.00.00      2       1292.0     112.0      9,4          955.0   \n",
       "2  10/03/2004  20.00.00    2,2       1402.0      88.0      9,0          939.0   \n",
       "3  10/03/2004  21.00.00    2,2       1376.0      80.0      9,2          948.0   \n",
       "4  10/03/2004  22.00.00    1,6       1272.0      51.0      6,5          836.0   \n",
       "\n",
       "   NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH  \\\n",
       "0    166.0        1056.0    113.0        1692.0       1268.0  13,6  48,9   \n",
       "1    103.0        1174.0     92.0        1559.0        972.0  13,3  47,7   \n",
       "2    131.0        1140.0    114.0        1555.0       1074.0  11,9  54,0   \n",
       "3    172.0        1092.0    122.0        1584.0       1203.0  11,0  60,0   \n",
       "4    131.0        1205.0    116.0        1490.0       1110.0  11,2  59,6   \n",
       "\n",
       "       AH  Unnamed: 15  Unnamed: 16  \n",
       "0  0,7578          NaN          NaN  \n",
       "1  0,7255          NaN          NaN  \n",
       "2  0,7502          NaN          NaN  \n",
       "3  0,7867          NaN          NaN  \n",
       "4  0,7888          NaN          NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9471 entries, 0 to 9470\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           9357 non-null   object \n",
      " 1   Time           9357 non-null   object \n",
      " 2   CO(GT)         9357 non-null   object \n",
      " 3   PT08.S1(CO)    9357 non-null   float64\n",
      " 4   NMHC(GT)       9357 non-null   float64\n",
      " 5   C6H6(GT)       9357 non-null   object \n",
      " 6   PT08.S2(NMHC)  9357 non-null   float64\n",
      " 7   NOx(GT)        9357 non-null   float64\n",
      " 8   PT08.S3(NOx)   9357 non-null   float64\n",
      " 9   NO2(GT)        9357 non-null   float64\n",
      " 10  PT08.S4(NO2)   9357 non-null   float64\n",
      " 11  PT08.S5(O3)    9357 non-null   float64\n",
      " 12  T              9357 non-null   object \n",
      " 13  RH             9357 non-null   object \n",
      " 14  AH             9357 non-null   object \n",
      " 15  Unnamed: 15    0 non-null      float64\n",
      " 16  Unnamed: 16    0 non-null      float64\n",
      "dtypes: float64(10), object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deal with NaN data. From the data above, we know that there are 3842 rows with NaN values, which represents 17.7% of the total values. Since this correspond to a small percentage, we proceed to delete the rows that contain Nan values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9471 entries, 0 to 9470\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           9357 non-null   object \n",
      " 1   Time           9357 non-null   object \n",
      " 2   CO(GT)         9357 non-null   object \n",
      " 3   PT08.S1(CO)    9357 non-null   float64\n",
      " 4   NMHC(GT)       9357 non-null   float64\n",
      " 5   C6H6(GT)       9357 non-null   object \n",
      " 6   PT08.S2(NMHC)  9357 non-null   float64\n",
      " 7   NOx(GT)        9357 non-null   float64\n",
      " 8   PT08.S3(NOx)   9357 non-null   float64\n",
      " 9   NO2(GT)        9357 non-null   float64\n",
      " 10  PT08.S4(NO2)   9357 non-null   float64\n",
      " 11  PT08.S5(O3)    9357 non-null   float64\n",
      " 12  T              9357 non-null   object \n",
      " 13  RH             9357 non-null   object \n",
      " 14  AH             9357 non-null   object \n",
      "dtypes: float64(8), object(7)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['Unnamed: 15'], axis=1)\n",
    "data = data.drop(['Unnamed: 16'], axis=1)\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>02/11/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>9,2</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>48,2</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2643.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>20,9</td>\n",
       "      <td>67,5</td>\n",
       "      <td>1,6539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>14/12/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>9,3</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200,0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>02/12/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>9,4</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>43,9</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>2069.0</td>\n",
       "      <td>15,4</td>\n",
       "      <td>73,0</td>\n",
       "      <td>1,2688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>26/10/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>9,5</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>52,1</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>22,5</td>\n",
       "      <td>61,5</td>\n",
       "      <td>1,6579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>13/12/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>9,9</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>50,8</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>2523.0</td>\n",
       "      <td>12,6</td>\n",
       "      <td>55,9</td>\n",
       "      <td>0,8142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  \\\n",
       "5690  02/11/2004  20.00.00    9,2       1778.0    -200.0     48,2   \n",
       "6696  14/12/2004  18.00.00    9,3       -200.0    -200.0   -200,0   \n",
       "6409  02/12/2004  19.00.00    9,4       1816.0    -200.0     43,9   \n",
       "5520  26/10/2004  18.00.00    9,5       1908.0    -200.0     52,1   \n",
       "6672  13/12/2004  18.00.00    9,9       1881.0    -200.0     50,8   \n",
       "\n",
       "      PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
       "5690         1935.0    859.0         349.0    119.0        2643.0   \n",
       "6696         -200.0   1310.0        -200.0    248.0        -200.0   \n",
       "6409         1851.0   1184.0         341.0    171.0        2405.0   \n",
       "5520         2007.0    952.0         325.0    180.0        2775.0   \n",
       "6672         1983.0   1479.0         334.0    269.0        2271.0   \n",
       "\n",
       "      PT08.S5(O3)     T    RH      AH  \n",
       "5690       1927.0  20,9  67,5  1,6539  \n",
       "6696       -200.0  -200  -200    -200  \n",
       "6409       2069.0  15,4  73,0  1,2688  \n",
       "5520       2372.0  22,5  61,5  1,6579  \n",
       "6672       2523.0  12,6  55,9  0,8142  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['CO(GT)'].tail()\n",
    "data.sort_values('CO(GT)').tail()\n",
    "#GT means gygatone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1592"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['CO(GT)'] == '-200'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-200    1592\n",
       "1,4      279\n",
       "1,6      275\n",
       "1,5      273\n",
       "1,1      262\n",
       "        ... \n",
       "10,1       1\n",
       "9,3        1\n",
       "7          1\n",
       "9,2        1\n",
       "9,9        1\n",
       "Name: CO(GT), Length: 104, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CO(GT)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13,6</td>\n",
       "      <td>48,9</td>\n",
       "      <td>0,7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13,3</td>\n",
       "      <td>47,7</td>\n",
       "      <td>0,7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>54,0</td>\n",
       "      <td>0,7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9,2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11,0</td>\n",
       "      <td>60,0</td>\n",
       "      <td>0,7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11,2</td>\n",
       "      <td>59,6</td>\n",
       "      <td>0,7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>30/04/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>4,4</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>19,5</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>19,1</td>\n",
       "      <td>61,1</td>\n",
       "      <td>1,3345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>30/04/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>3,1</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>15,1</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>18,2</td>\n",
       "      <td>65,4</td>\n",
       "      <td>1,3529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>30/04/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>14,6</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>18,1</td>\n",
       "      <td>66,1</td>\n",
       "      <td>1,3579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>30/04/2004</td>\n",
       "      <td>23.00.00</td>\n",
       "      <td>3,1</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>13,7</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>17,7</td>\n",
       "      <td>66,9</td>\n",
       "      <td>1,3422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>01/05/2004</td>\n",
       "      <td>00.00.00</td>\n",
       "      <td>3,5</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>15,2</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>17,8</td>\n",
       "      <td>66,8</td>\n",
       "      <td>1,3460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  \\\n",
       "0     10/03/2004  18.00.00    2,6       1360.0     150.0     11,9   \n",
       "1     10/03/2004  19.00.00      2       1292.0     112.0      9,4   \n",
       "2     10/03/2004  20.00.00    2,2       1402.0      88.0      9,0   \n",
       "3     10/03/2004  21.00.00    2,2       1376.0      80.0      9,2   \n",
       "4     10/03/2004  22.00.00    1,6       1272.0      51.0      6,5   \n",
       "...          ...       ...    ...          ...       ...      ...   \n",
       "1226  30/04/2004  20.00.00    4,4       1449.0     501.0     19,5   \n",
       "1227  30/04/2004  21.00.00    3,1       1363.0     234.0     15,1   \n",
       "1228  30/04/2004  22.00.00      3       1371.0     212.0     14,6   \n",
       "1229  30/04/2004  23.00.00    3,1       1406.0     275.0     13,7   \n",
       "1230  01/05/2004  00.00.00    3,5       1425.0     275.0     15,2   \n",
       "\n",
       "      PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
       "0            1046.0    166.0        1056.0    113.0        1692.0   \n",
       "1             955.0    103.0        1174.0     92.0        1559.0   \n",
       "2             939.0    131.0        1140.0    114.0        1555.0   \n",
       "3             948.0    172.0        1092.0    122.0        1584.0   \n",
       "4             836.0    131.0        1205.0    116.0        1490.0   \n",
       "...             ...      ...           ...      ...           ...   \n",
       "1226         1282.0    254.0         625.0    133.0        2100.0   \n",
       "1227         1152.0    189.0         684.0    110.0        1951.0   \n",
       "1228         1136.0    174.0         689.0    102.0        1927.0   \n",
       "1229         1107.0    167.0         718.0    108.0        1872.0   \n",
       "1230         1155.0    185.0         709.0    110.0        1936.0   \n",
       "\n",
       "      PT08.S5(O3)     T    RH      AH  \n",
       "0          1268.0  13,6  48,9  0,7578  \n",
       "1           972.0  13,3  47,7  0,7255  \n",
       "2          1074.0  11,9  54,0  0,7502  \n",
       "3          1203.0  11,0  60,0  0,7867  \n",
       "4          1110.0  11,2  59,6  0,7888  \n",
       "...           ...   ...   ...     ...  \n",
       "1226       1569.0  19,1  61,1  1,3345  \n",
       "1227       1495.0  18,2  65,4  1,3529  \n",
       "1228       1471.0  18,1  66,1  1,3579  \n",
       "1229       1384.0  17,7  66,9  1,3422  \n",
       "1230       1789.0  17,8  66,8  1,3460  \n",
       "\n",
       "[851 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data != -200).all(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13,6</td>\n",
       "      <td>48,9</td>\n",
       "      <td>0,7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13,3</td>\n",
       "      <td>47,7</td>\n",
       "      <td>0,7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>54,0</td>\n",
       "      <td>0,7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9,2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11,0</td>\n",
       "      <td>60,0</td>\n",
       "      <td>0,7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11,2</td>\n",
       "      <td>59,6</td>\n",
       "      <td>0,7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>10.00.00</td>\n",
       "      <td>3,1</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>13,5</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>21,9</td>\n",
       "      <td>29,3</td>\n",
       "      <td>0,7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>11.00.00</td>\n",
       "      <td>2,4</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>11,4</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>24,3</td>\n",
       "      <td>23,7</td>\n",
       "      <td>0,7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>12.00.00</td>\n",
       "      <td>2,4</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>12,4</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>26,9</td>\n",
       "      <td>18,3</td>\n",
       "      <td>0,6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>13.00.00</td>\n",
       "      <td>2,1</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>9,5</td>\n",
       "      <td>961.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>28,3</td>\n",
       "      <td>13,5</td>\n",
       "      <td>0,5139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>14.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>28,5</td>\n",
       "      <td>13,1</td>\n",
       "      <td>0,5028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9357 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  \\\n",
       "0     10/03/2004  18.00.00    2,6       1360.0     150.0     11,9   \n",
       "1     10/03/2004  19.00.00      2       1292.0     112.0      9,4   \n",
       "2     10/03/2004  20.00.00    2,2       1402.0      88.0      9,0   \n",
       "3     10/03/2004  21.00.00    2,2       1376.0      80.0      9,2   \n",
       "4     10/03/2004  22.00.00    1,6       1272.0      51.0      6,5   \n",
       "...          ...       ...    ...          ...       ...      ...   \n",
       "9352  04/04/2005  10.00.00    3,1       1314.0    -200.0     13,5   \n",
       "9353  04/04/2005  11.00.00    2,4       1163.0    -200.0     11,4   \n",
       "9354  04/04/2005  12.00.00    2,4       1142.0    -200.0     12,4   \n",
       "9355  04/04/2005  13.00.00    2,1       1003.0    -200.0      9,5   \n",
       "9356  04/04/2005  14.00.00    2,2       1071.0    -200.0     11,9   \n",
       "\n",
       "      PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
       "0            1046.0    166.0        1056.0    113.0        1692.0   \n",
       "1             955.0    103.0        1174.0     92.0        1559.0   \n",
       "2             939.0    131.0        1140.0    114.0        1555.0   \n",
       "3             948.0    172.0        1092.0    122.0        1584.0   \n",
       "4             836.0    131.0        1205.0    116.0        1490.0   \n",
       "...             ...      ...           ...      ...           ...   \n",
       "9352         1101.0    472.0         539.0    190.0        1374.0   \n",
       "9353         1027.0    353.0         604.0    179.0        1264.0   \n",
       "9354         1063.0    293.0         603.0    175.0        1241.0   \n",
       "9355          961.0    235.0         702.0    156.0        1041.0   \n",
       "9356         1047.0    265.0         654.0    168.0        1129.0   \n",
       "\n",
       "      PT08.S5(O3)     T    RH      AH  \n",
       "0          1268.0  13,6  48,9  0,7578  \n",
       "1           972.0  13,3  47,7  0,7255  \n",
       "2          1074.0  11,9  54,0  0,7502  \n",
       "3          1203.0  11,0  60,0  0,7867  \n",
       "4          1110.0  11,2  59,6  0,7888  \n",
       "...           ...   ...   ...     ...  \n",
       "9352       1729.0  21,9  29,3  0,7568  \n",
       "9353       1269.0  24,3  23,7  0,7119  \n",
       "9354       1092.0  26,9  18,3  0,6406  \n",
       "9355        770.0  28,3  13,5  0,5139  \n",
       "9356        816.0  28,5  13,1  0,5028  \n",
       "\n",
       "[9357 rows x 15 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2,6\n",
       "1         2\n",
       "2       2,2\n",
       "3       2,2\n",
       "4       1,6\n",
       "       ... \n",
       "9352    3,1\n",
       "9353    2.4\n",
       "9354    2.4\n",
       "9355    2,1\n",
       "9356    2,2\n",
       "Name: CO(GT), Length: 9357, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CO(GT)'] = data['CO(GT)'].replace(\",\",\" \")\n",
    "data['CO(GT)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.6\n",
       "1         2\n",
       "2       2.2\n",
       "3       2.2\n",
       "4       1.6\n",
       "       ... \n",
       "9352    3.1\n",
       "9353    2.4\n",
       "9354    2.4\n",
       "9355    2.1\n",
       "9356    2.2\n",
       "Name: CO(GT), Length: 9357, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CO(GT)'] = data['CO(GT)'].astype(str)\n",
    "data['CO(GT)'] = data['CO(GT)'].str.replace(\",\",\".\")\n",
    "data['CO(GT)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       11.9\n",
       "1        9.4\n",
       "2        9.0\n",
       "3        9.2\n",
       "4        6.5\n",
       "        ... \n",
       "9352    13.5\n",
       "9353    11.4\n",
       "9354    12.4\n",
       "9355     9.5\n",
       "9356    11.9\n",
       "Name: C6H6(GT), Length: 9357, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['C6H6(GT)'] = data['C6H6(GT)'].str.replace(\",\",\".\")\n",
    "data['C6H6(GT)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       13.6\n",
       "1       13.3\n",
       "2       11.9\n",
       "3       11.0\n",
       "4       11.2\n",
       "        ... \n",
       "9352    21.9\n",
       "9353    24.3\n",
       "9354    26.9\n",
       "9355    28.3\n",
       "9356    28.5\n",
       "Name: T, Length: 9357, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['T'] = data['T'].str.replace(\",\",\".\")\n",
    "data['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       48.9\n",
       "1       47.7\n",
       "2       54.0\n",
       "3       60.0\n",
       "4       59.6\n",
       "        ... \n",
       "9352    29.3\n",
       "9353    23.7\n",
       "9354    18.3\n",
       "9355    13.5\n",
       "9356    13.1\n",
       "Name: RH, Length: 9357, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['RH'] = data['RH'].str.replace(\",\",\".\")\n",
    "data['RH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.7578\n",
       "1       0.7255\n",
       "2       0.7502\n",
       "3       0.7867\n",
       "4       0.7888\n",
       "         ...  \n",
       "9352    0.7568\n",
       "9353    0.7119\n",
       "9354    0.6406\n",
       "9355    0.5139\n",
       "9356    0.5028\n",
       "Name: AH, Length: 9357, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AH'] = data['AH'].str.replace(\",\",\".\")\n",
    "data['AH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this first screening, we can see that sqft_basement is an object, so we convert it into float. But when we try to apply the function astype, it gives an error. That's why we have to epxlore the column a little further. By reading the corresponding error of astype and using the function .value_counts() we can see that the problem is that there is the sign \"?\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed with our analysis, we detete the rows that contain \"?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.sqft_basement != '?' )]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed to convert sqft_basement into a float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sqft_basement'] = data['sqft_basement'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have confirm that the sqft_basement is now a float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATEGORICAL VS CONTINUOUS DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's identify which variables are categorical and which ones are continuous. We will do it by plotting the data. From the graphs below, we can determine that waterfront, view, condition, grade, years built, renovated year, number of bedrooms, numbero of bathrooms and number of floors are categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    " # crate the figure and axes\n",
    "fig, axes = plt.subplots(7, 3, figsize=(24, 30))   \n",
    "\n",
    "# unpack all the axes subplots\n",
    "axe = axes.ravel()\n",
    "\n",
    "# assign the plot to each subplot in axe\n",
    "for i, c in enumerate(data.columns):\n",
    "    \n",
    "    data.plot(kind='scatter', x=c, y='price', ax=axe[i], alpha=0.4, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conver the \"years_built\" variable into a continous variable by calculating the years since it was renovated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['years_built'] = 2022 - data['yr_built']\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFFECT OF RENOVATION ON PRICE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our analysis determining the effect of renovation in house prices. Let's explore the data a bit further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.yr_renovated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data, we can observed that some years of renovation correspond to 0, which means that these houses have not been renovated. \n",
    "What we are going to do, is to create 2 grups, one of houses that have not been renovated and the other one of renovated houses. After that, we will perform a t-test to determine whether there is a significant change between these two groups. \n",
    "\n",
    "\n",
    "Hypothesis:\n",
    "H0 = there are no differences between renovated and non-renovated houses\n",
    "Ha = there are differences between renovated and non-renovated houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_renovated = data[data.yr_renovated == 0]['price']\n",
    "renovated = data[data.yr_renovated != 0]['price']\n",
    "\n",
    "# Calculate the 2-sided p-value for a t-test comparing the renovated vs no-renovated groups\n",
    "from scipy import stats\n",
    "\n",
    "stats.ttest_ind(no_renovated, renovated, equal_var=False)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result indicates that there is a signfincant difference between renovated and non-renovated houeses. Which one is more expensive? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(no_renovated.mean(), renovated.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The renovated houses are more expensive. How much?  1.4-fold more expensive, as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_increase = (renovated.mean()/no_renovated.mean())\n",
    "fold_increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data, we select only the non-renovated houses, as our main is to find the cheapest houses for the WHPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.drop(data[data.yr_renovated != 0].index)\n",
    "data_new.yr_renovated.value_counts() #to confirm that we only selected the non-renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFFECTS OF WATERVIEW ON PRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study the effect of waterviews on price, we performed the same analysis that with renovation: a t-test to compare houses with and without waterview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_water_view = data_new[data_new.waterfront == 0]['price']\n",
    "water_view = data_new[data_new.waterfront != 0]['price']\n",
    "\n",
    "# Calculate the 2-sided p-value for a t-test comparing the renovated vs no-renovated groups\n",
    "from scipy import stats\n",
    "\n",
    "stats.ttest_ind(water_view, no_water_view, equal_var=False)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test analysis confirm that there is a statistically signifcant differences between houses with and whithout waterview. \n",
    "Below we can see the average price for both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(water_view.mean(), no_water_view.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data above, we select only the houses that do not have waterviews for our further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data_new.drop(data_new[data_new.waterfront != 0].index)\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.waterfront.value_counts() #to confirm that we only have the houses without waterviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFFECTS OF ZIPCODES ON PRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want now to determine which are the zipcodes that are most expensive. Since zipcodes is a categorical variable, we will use get_dummies to work with tat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_dummies = pd.get_dummies(data_new['zipcode'], prefix='zip', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_analysis = data.drop(['zipcode'], axis=1)\n",
    "zipcode_analysis = pd.concat([data_new['price'], zipcode_dummies], axis=1)\n",
    "zipcode_analysis.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_zip = zipcode_analysis.drop('price', axis=1)\n",
    "y_zip = zipcode_analysis['price']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_zip_int = sm.add_constant(X_zip)\n",
    "model = sm.OLS(y_zip,X_zip_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted R-squared value for the whole mode is 0.457, which is a very low value. This means that only 45% of the price variability can be explained by zipcode. However, in this analysis we want to focus on particular zipcodes. \n",
    "\n",
    "From this analysis we can see that several zipocdes positively and signifcantly increase the price (coefient positive and p < 0.05), and some that do not. We also observe that even some of them have a negative correlation with price, they are not significant. \n",
    "\n",
    "We want to identify which ones are the ones that positively and signficnatly increase the price and which ones do not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['index','pvalue']\n",
    "\n",
    "pvalue_positive_table = pd.DataFrame(columns=columns)\n",
    "pvalue_negative_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for i, a in enumerate(model.pvalues):\n",
    "    if a < 0.05:\n",
    "        pvalue_positive_table.loc[i] = [i,a]\n",
    "    else:\n",
    "        pvalue_negative_table.loc[i] = [i,a]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_positive_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_negative_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pvalue_negative_table.index\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes_of_interstet = []\n",
    "\n",
    "for i in index:\n",
    "    zipcodes_of_interstet.append(zipcode_analysis.columns[i])\n",
    "\n",
    "zipcodes_of_interstet_name = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see the zipcodes of interset, which means, the zipcodes that do not signficnatly incrase the house prices. Herein, these zipcodes are the ones that will have the lowest house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zipcodes_of_interstet:\n",
    "     zipcodes_of_interstet_name.append(i[-5:])\n",
    "\n",
    "zipcodes_of_interstet_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_NO_interest = pvalue_positive_table.index\n",
    "\n",
    "\n",
    "zipcodes_of_NO_interstet = []\n",
    "\n",
    "for i in index_NO_interest:\n",
    "    zipcodes_of_NO_interstet.append(zipcode_analysis.columns[i])\n",
    "\n",
    "zipcodes_of_NO_interstet_name = []\n",
    "\n",
    "for i in zipcodes_of_NO_interstet:\n",
    "     zipcodes_of_NO_interstet_name.append(i[-5:])\n",
    "\n",
    "zipcodes_of_NO_interstet_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to refresh our data:\n",
    "\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as mentioend above, now we want to select only the houses corresponding to our zipcodes of interest\n",
    "\n",
    "data_new2 =  data_new[data_new['zipcode'].isin(zipcodes_of_interstet_name)]\n",
    "data_new2.zipcode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFFECTS OF CONDITION ON PRICE\n",
    "\n",
    "Condition is also a categorical variable, and we will apply get_dummies to deal with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_dummies = pd.get_dummies(data_new2['condition'], prefix='cond', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_analysis = data_new2.drop(['condition'], axis=1)\n",
    "condition_analysis = pd.concat([data_new2['price'], condition_dummies], axis=1)\n",
    "condition_analysis.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cond = condition_analysis.drop('price', axis=1)\n",
    "y_cond = condition_analysis['price']\n",
    "\n",
    "X_cond_int = sm.add_constant(X_cond)\n",
    "model_cond = sm.OLS(y_cond,X_cond_int).fit()\n",
    "model_cond.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted R2-value is very low (0.015). It means that only 1.5% of the price variablity can be explained by this model. However, we have performed this analysis to focus on the value of each condition individually. \n",
    "\n",
    "Similar to zipcodes, there are some conditoins that signicnatly and positively increase the house price. We perform the same analysis to udnerstand which conditions impact the price and which ones do not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['index','pvalue']\n",
    "\n",
    "condition_pvalue_positive_table = pd.DataFrame(columns=columns)\n",
    "condition_pvalue_negative_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for i, a in enumerate(model_cond.pvalues):\n",
    "    if a < 0.05:\n",
    "        condition_pvalue_positive_table.loc[i] = [i,a]\n",
    "    else:\n",
    "        condition_pvalue_negative_table.loc[i] = [i,a]\n",
    "\n",
    "\n",
    "condition_pvalue_positive_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_pvalue_negative_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_grade = condition_pvalue_negative_table.index\n",
    "cond_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_of_interstet = []\n",
    "\n",
    "for i in cond_grade:\n",
    "    cond_of_interstet.append(condition_analysis.columns[i])\n",
    "\n",
    "cond_of_interstet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_grade_negative = condition_pvalue_positive_table.index\n",
    "cond_grade_negative\n",
    "\n",
    "cond_no_interstet = []\n",
    "\n",
    "for i in cond_grade_negative:\n",
    "    cond_no_interstet.append(condition_analysis.columns[i])\n",
    "\n",
    "cond_no_interstet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new2.condition.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the analysis above, we can conclude that condition 3 and above signficnatly increase the price of the houses. However, we can't filter our data only based on condition 1 and 2, because this only correspond to 27 datapoints. We will proceed with the analysis without this filter, but this is an insight that we will give to our clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFFECTS OF GRADE ON PRICE\n",
    "\n",
    "Grade is also a categorical variable, and we will apply get_dummies to deal with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_dummies = pd.get_dummies(data_new2['grade'], prefix='grd', drop_first=True)\n",
    "\n",
    "grade_analysis = data_new2.drop(['grade'], axis=1)\n",
    "grade_analysis = pd.concat([data_new2['price'], grade_dummies], axis=1)\n",
    "grade_analysis.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grade = grade_analysis.drop('price', axis=1)\n",
    "y_grade = grade_analysis['price']\n",
    "\n",
    "X_grade_int = sm.add_constant(X_grade)\n",
    "model_grade = sm.OLS(y_grade,X_grade_int).fit()\n",
    "model_grade.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to condition, the adjusted R2-value is very low (0.433). This means that only 43.3% of the price variability can be explained by this model. However, we have performed this analysis to focus on the value of each grade indivually. \n",
    "\n",
    "Similar to grade, there are some grades that signficantly and positively increase the house price. We perform the same analysis to understand which grades impact the price and which ones do not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['index','pvalue']\n",
    "\n",
    "grade_pvalue_positive_table = pd.DataFrame(columns=columns)\n",
    "grade_pvalue_negative_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for i, a in enumerate(model_grade.pvalues):\n",
    "    if a < 0.05:\n",
    "        grade_pvalue_positive_table.loc[i] = [i,a]\n",
    "    else:\n",
    "        grade_pvalue_negative_table.loc[i] = [i,a]\n",
    "\n",
    "\n",
    "grade_pvalue_positive_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_pvalue_negative_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_grade = grade_pvalue_negative_table.index\n",
    "index_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_of_interstet = []\n",
    "\n",
    "for i in index_grade:\n",
    "    grade_of_interstet.append(grade_analysis.columns[i])\n",
    "\n",
    "grade_of_interstet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_grade_pos = grade_pvalue_positive_table.index\n",
    "\n",
    "grade_no_interstet = []\n",
    "\n",
    "for i in index_grade_pos:\n",
    "    grade_no_interstet.append(grade_analysis.columns[i])\n",
    "\n",
    "grade_no_interstet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis above, we can determine that grade 9 and above significantly increase the house price, and therefore we  select only the houses with grade bewlow 9, as they are the cheaper ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "grade_of_interstet_name = []\n",
    "\n",
    "for i in grade_of_interstet:\n",
    "     grade_of_interstet_name.append(i[-1:])\n",
    "\n",
    "grade_of_interstet_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select houses below grade 9\n",
    "data_new3 =  data_new2[data_new2['grade'].isin(grade_of_interstet_name)]\n",
    "\n",
    "data_new3.grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFFECTS OF NUMBER OF BEDROOMS ON PRICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms_dummies = pd.get_dummies(data_new3['bedrooms'], prefix='bdr', drop_first=True)\n",
    "\n",
    "bedrooms_analysis = data_new3.drop(['grade'], axis=1)\n",
    "bedrooms_analysis = pd.concat([data_new3['price'], bedrooms_dummies], axis=1)\n",
    "bedrooms_analysis.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bed = bedrooms_analysis.drop('price', axis=1)\n",
    "y_bed = bedrooms_analysis['price']\n",
    "\n",
    "X_bed_int = sm.add_constant(X_bed)\n",
    "model_beds = sm.OLS(y_bed,X_bed_int).fit()\n",
    "model_beds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted R-squared value for the whole model is 0.132, which is a very low value. This means that only 13.2% of the price variability can be explained by this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['index','pvalue']\n",
    "\n",
    "bedrooms_pvalue_positive_table = pd.DataFrame(columns=columns)\n",
    "bedrooms_pvalue_negative_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for i, a in enumerate(model_beds.pvalues):\n",
    "    if a < 0.05:\n",
    "        bedrooms_pvalue_positive_table.loc[i] = [i,a]\n",
    "    else:\n",
    "        bedrooms_pvalue_negative_table.loc[i] = [i,a]\n",
    "\n",
    "\n",
    "bedrooms_pvalue_positive_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms_pvalue_negative_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this analysis indicate, is that the number of bedrooms always have an impact on the price. And the more number of rooms, the more expensive the price (since the coeficient increases with number of rooms).\n",
    "It will be up to WHPO to decide the number of rooms they want for their houses. Maybe they want one room for single people, or 3 for families.... but they need to be aware that the bigger the number of rooms, the more expensive the houses.\n",
    "Considering that WHPO may be intersted in different houses sizes, we won't furhter narrow our subset of intersting houses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the houses with the lowest price, we want to determine how several continuous variables affect the price of the selected houses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EFFECTS OF YEARS SINCE BUILT, SQFT LIVING AREA AND SQFT LIVING LOT ON PRICE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We focus on the following variables, which are continuous variables:\n",
    "\n",
    "continuous_norm = ['price','sqft_living','sqft_lot', 'years_built']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if these variables follow a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.gca()\n",
    "data_new3[continuous_norm].hist(ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to improve the distribution by logaritmic transformation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Log transform and normalize\n",
    "data_cont = data_new3[continuous_norm]\n",
    "\n",
    "# log features\n",
    "log_names = [f'{column}_log' for column in data_cont.columns]\n",
    "data_log = np.log(data_cont)\n",
    "data_log.columns = log_names\n",
    "# normalize (subract mean and divide by std)\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "data_log_norm = data_log.apply(normalize)\n",
    "\n",
    "data_log_norm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the changes in the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.gca()\n",
    "data_log_norm.hist(ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's confirm the data that we have\n",
    "\n",
    "data_log_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a regression model with these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = data_log_norm.drop('price_log', axis=1)\n",
    "y_new = data_log_norm['price_log']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_new_int = sm.add_constant(X_new)\n",
    "model_new = sm.OLS(y_new,X_new_int).fit()\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The adjusted R-squared value for the whole mode is 0.446, which is a  low value. This means that only 44.6% of the price variability can be explained by this model.\n",
    "To try to improve our model, let's check the colinearility of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_norm.corr()\n",
    "abs(data_log_norm.corr()) > 0.75\n",
    "\n",
    "# save absolute value of correlation matrix as a data frame\n",
    "# converts all values to absolute value\n",
    "# stacks the row:column pairs into a multindex\n",
    "# reset the index to set the multindex to seperate columns\n",
    "# sort values. 0 is the column automatically generated by the stacking\n",
    "df=data_log_norm.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df['pairs'] = list(zip(df.level_0, df.level_1))\n",
    "# set index to pairs\n",
    "df.set_index(['pairs'], inplace = True)\n",
    "#d rop level columns\n",
    "df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "# rename correlation column as cc rather than 0\n",
    "df.columns = ['cc']\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "# for the sake of exercise, kept it in.\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df[(df.cc>.75) & (df.cc <1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis above, it doesn't seem to be any considerable correlation between variables. Now let's study interaction between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "regression = LinearRegression()\n",
    "\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X_new, y_new, scoring='r2', cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "interactions = []\n",
    "\n",
    "feat_combinations = combinations(X_new.columns, 2)\n",
    "\n",
    "data = X_new.copy()\n",
    "for i, (a, b) in enumerate(feat_combinations):\n",
    "    data['interaction'] = data[a] * data[b]\n",
    "    score = np.mean(cross_val_score(regression, data, y_new, scoring='r2', cv=crossvalidation))\n",
    "    if score > baseline:\n",
    "        interactions.append((a, b, round(score,3)))\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "            \n",
    "print('Top interaction: %s' %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the analysis above, there are not interactions or colinearitly that we should we aware and adjust our model based on. As such, let's refresh our model and gain some insights: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = data_log_norm.drop('price_log', axis=1)\n",
    "y_new = data_log_norm['price_log']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_new_int = sm.add_constant(X_new)\n",
    "model_new = sm.OLS(y_new,X_new_int).fit()\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQFT living area and lot have a significant positive contribution to the house price in our subset of interest (the more area, the more expensive).\n",
    "Years since built has a significant negative contribution to the price (the oldest, the cheapest).\n",
    "sqft living area is the variable that affects the most to the price, as it has the highest coefficient value (coef = 0.56) and a p_value < 0.05.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we validate our model creating a test sample with 20% of the datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squarred Error:', train_mse)\n",
    "print('Test Mean Squarred Error:', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that there are no big difference between Test mean squarred error and Train mean squarred error validates our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS\n",
    "We provide the following business recomendations:\n",
    "\n",
    "* **Recommendations 1**: Look for non-renovated houses.\n",
    "* **Recommendations 2**: Look for houses that have no waterview.\n",
    "* **Recommendations 3**: Look for houses in the following zipcodes: 98002, 98003, 98022, 98023, 98030, 98031, 98032, 98055, 98106, 98148, 98168, 98178, 98188, 98198.\n",
    "* **Recommendations 4**: Look for houses below condition 3.\n",
    "* **Recommendations 5**: Look for houses below grade 9.\n",
    "* **Recommendations 6**: center your search on houses with the lowest sqft living. Older houses will be cheaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
